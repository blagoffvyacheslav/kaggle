{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dataset import *\n",
    "from helpers.ipython import *\n",
    "from helpers.model import *\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_y():\n",
    "    return data.get('train', col='Category')\n",
    "\n",
    "def get_X(dset='train'):\n",
    "    return data.extract(dset, [\n",
    "        ('data', ['X', 'Y']),\n",
    "        ('data', ['DayOfWeek', 'PdDistrict', 'Address']),\n",
    "        ('dates', ['year', 'month', 'week', 'hour', 'minute']),\n",
    "        ('addr', ['street', 'corner']),\n",
    "    ])\n",
    "\n",
    "X, y = get_X(), get_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def random_weeks_select(df, num_years=10, num_weeks=1):\n",
    "    select = df['year'] < 0\n",
    "    years = range(2003, 2016)\n",
    "\n",
    "    for y in range(0, num_years):\n",
    "        year = random.choice(years)\n",
    "        years.remove(year)\n",
    "        weeks = range(0, 53, 2)\n",
    "        \n",
    "        for w in range(0, num_weeks):\n",
    "            while True:\n",
    "                week = random.choice(weeks)\n",
    "                weeks.remove(week)\n",
    "                sel = (df['year'] == year) & (df['week'] == week)\n",
    "                if (len(df[sel]) > 0):\n",
    "                    select = select | sel\n",
    "                    break\n",
    "\n",
    "    return select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "select = X['year'].isin([2005, 2010])\n",
    "X_train, X_eval, y_train, y_eval = skl.cross_validation.train_test_split(\n",
    "    X[select], y[select], train_size=0.7, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_depth - 3, min_child_weight - 1\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.147186\n",
      "[10]\tvalidation_0-mlogloss:2.482694\n",
      "[20]\tvalidation_0-mlogloss:2.395326\n",
      "[30]\tvalidation_0-mlogloss:2.368134\n",
      "[40]\tvalidation_0-mlogloss:2.355088\n",
      "[50]\tvalidation_0-mlogloss:2.346726\n",
      "[60]\tvalidation_0-mlogloss:2.340412\n",
      "[70]\tvalidation_0-mlogloss:2.335127\n",
      "[80]\tvalidation_0-mlogloss:2.330131\n",
      "[90]\tvalidation_0-mlogloss:2.326790\n",
      "[100]\tvalidation_0-mlogloss:2.323601\n",
      "[110]\tvalidation_0-mlogloss:2.321689\n",
      "[120]\tvalidation_0-mlogloss:2.318969\n",
      "[130]\tvalidation_0-mlogloss:2.317125\n",
      "[140]\tvalidation_0-mlogloss:2.315545\n",
      "[150]\tvalidation_0-mlogloss:2.314903\n",
      "[160]\tvalidation_0-mlogloss:2.313872\n",
      "[170]\tvalidation_0-mlogloss:2.312513\n",
      "[180]\tvalidation_0-mlogloss:2.311659\n",
      "[190]\tvalidation_0-mlogloss:2.310882\n",
      "[200]\tvalidation_0-mlogloss:2.310163\n",
      "[210]\tvalidation_0-mlogloss:2.309672\n",
      "[220]\tvalidation_0-mlogloss:2.308841\n",
      "[230]\tvalidation_0-mlogloss:2.308480\n",
      "[240]\tvalidation_0-mlogloss:2.308176\n",
      "[250]\tvalidation_0-mlogloss:2.307842\n",
      "[260]\tvalidation_0-mlogloss:2.307628\n",
      "[270]\tvalidation_0-mlogloss:2.307912\n",
      "[280]\tvalidation_0-mlogloss:2.307789\n",
      "[290]\tvalidation_0-mlogloss:2.307565\n",
      "[300]\tvalidation_0-mlogloss:2.307562\n",
      "[310]\tvalidation_0-mlogloss:2.308015\n",
      "Stopping. Best iteration:\n",
      "[297]\tvalidation_0-mlogloss:2.307324\n",
      "\n",
      "max_depth - 3, min_child_weight - 3\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.147204\n",
      "[10]\tvalidation_0-mlogloss:2.482729\n",
      "[20]\tvalidation_0-mlogloss:2.397058\n",
      "[30]\tvalidation_0-mlogloss:2.369055\n",
      "[40]\tvalidation_0-mlogloss:2.355990\n",
      "[50]\tvalidation_0-mlogloss:2.347322\n",
      "[60]\tvalidation_0-mlogloss:2.340552\n",
      "[70]\tvalidation_0-mlogloss:2.336426\n",
      "[80]\tvalidation_0-mlogloss:2.331122\n",
      "[90]\tvalidation_0-mlogloss:2.327333\n",
      "[100]\tvalidation_0-mlogloss:2.324434\n",
      "[110]\tvalidation_0-mlogloss:2.321989\n",
      "[120]\tvalidation_0-mlogloss:2.319476\n",
      "[130]\tvalidation_0-mlogloss:2.317356\n",
      "[140]\tvalidation_0-mlogloss:2.315279\n",
      "[150]\tvalidation_0-mlogloss:2.314198\n",
      "[160]\tvalidation_0-mlogloss:2.312815\n",
      "[170]\tvalidation_0-mlogloss:2.312116\n",
      "[180]\tvalidation_0-mlogloss:2.310961\n",
      "[190]\tvalidation_0-mlogloss:2.309969\n",
      "[200]\tvalidation_0-mlogloss:2.309259\n",
      "[210]\tvalidation_0-mlogloss:2.308481\n",
      "[220]\tvalidation_0-mlogloss:2.308072\n",
      "[230]\tvalidation_0-mlogloss:2.307572\n",
      "[240]\tvalidation_0-mlogloss:2.307136\n",
      "[250]\tvalidation_0-mlogloss:2.306853\n",
      "[260]\tvalidation_0-mlogloss:2.306479\n",
      "[270]\tvalidation_0-mlogloss:2.306040\n",
      "[280]\tvalidation_0-mlogloss:2.305714\n",
      "[290]\tvalidation_0-mlogloss:2.305857\n",
      "Stopping. Best iteration:\n",
      "[276]\tvalidation_0-mlogloss:2.305653\n",
      "\n",
      "max_depth - 3, min_child_weight - 5\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.146472\n",
      "[10]\tvalidation_0-mlogloss:2.483781\n",
      "[20]\tvalidation_0-mlogloss:2.398392\n",
      "[30]\tvalidation_0-mlogloss:2.370069\n",
      "[40]\tvalidation_0-mlogloss:2.355339\n",
      "[50]\tvalidation_0-mlogloss:2.346996\n",
      "[60]\tvalidation_0-mlogloss:2.340296\n",
      "[70]\tvalidation_0-mlogloss:2.334797\n",
      "[80]\tvalidation_0-mlogloss:2.330249\n",
      "[90]\tvalidation_0-mlogloss:2.326040\n",
      "[100]\tvalidation_0-mlogloss:2.323303\n",
      "[110]\tvalidation_0-mlogloss:2.321111\n",
      "[120]\tvalidation_0-mlogloss:2.319441\n",
      "[130]\tvalidation_0-mlogloss:2.317497\n",
      "[140]\tvalidation_0-mlogloss:2.315785\n",
      "[150]\tvalidation_0-mlogloss:2.314451\n",
      "[160]\tvalidation_0-mlogloss:2.313269\n",
      "[170]\tvalidation_0-mlogloss:2.312193\n",
      "[180]\tvalidation_0-mlogloss:2.311035\n",
      "[190]\tvalidation_0-mlogloss:2.310290\n",
      "[200]\tvalidation_0-mlogloss:2.309583\n",
      "[210]\tvalidation_0-mlogloss:2.309076\n",
      "[220]\tvalidation_0-mlogloss:2.308039\n",
      "[230]\tvalidation_0-mlogloss:2.307357\n",
      "[240]\tvalidation_0-mlogloss:2.306904\n",
      "[250]\tvalidation_0-mlogloss:2.306246\n",
      "[260]\tvalidation_0-mlogloss:2.305984\n",
      "[270]\tvalidation_0-mlogloss:2.305437\n",
      "[280]\tvalidation_0-mlogloss:2.305000\n",
      "[290]\tvalidation_0-mlogloss:2.304599\n",
      "[300]\tvalidation_0-mlogloss:2.304025\n",
      "[310]\tvalidation_0-mlogloss:2.303452\n",
      "[320]\tvalidation_0-mlogloss:2.303253\n",
      "[330]\tvalidation_0-mlogloss:2.303153\n",
      "[340]\tvalidation_0-mlogloss:2.303209\n",
      "[350]\tvalidation_0-mlogloss:2.303272\n",
      "Stopping. Best iteration:\n",
      "[331]\tvalidation_0-mlogloss:2.303111\n",
      "\n",
      "max_depth - 5, min_child_weight - 1\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.083802\n",
      "[10]\tvalidation_0-mlogloss:2.429299\n",
      "[20]\tvalidation_0-mlogloss:2.346839\n",
      "[30]\tvalidation_0-mlogloss:2.323887\n",
      "[40]\tvalidation_0-mlogloss:2.313327\n",
      "[50]\tvalidation_0-mlogloss:2.307544\n",
      "[60]\tvalidation_0-mlogloss:2.303833\n",
      "[70]\tvalidation_0-mlogloss:2.301900\n",
      "[80]\tvalidation_0-mlogloss:2.300267\n",
      "[90]\tvalidation_0-mlogloss:2.299505\n",
      "[100]\tvalidation_0-mlogloss:2.299426\n",
      "[110]\tvalidation_0-mlogloss:2.298732\n",
      "[120]\tvalidation_0-mlogloss:2.299480\n",
      "Stopping. Best iteration:\n",
      "[107]\tvalidation_0-mlogloss:2.298693\n",
      "\n",
      "max_depth - 5, min_child_weight - 3\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.083980\n",
      "[10]\tvalidation_0-mlogloss:2.429768\n",
      "[20]\tvalidation_0-mlogloss:2.347309\n",
      "[30]\tvalidation_0-mlogloss:2.325489\n",
      "[40]\tvalidation_0-mlogloss:2.314672\n",
      "[50]\tvalidation_0-mlogloss:2.308517\n",
      "[60]\tvalidation_0-mlogloss:2.305063\n",
      "[70]\tvalidation_0-mlogloss:2.303229\n",
      "[80]\tvalidation_0-mlogloss:2.301382\n",
      "[90]\tvalidation_0-mlogloss:2.299755\n",
      "[100]\tvalidation_0-mlogloss:2.298993\n",
      "[110]\tvalidation_0-mlogloss:2.298368\n",
      "[120]\tvalidation_0-mlogloss:2.298552\n",
      "[130]\tvalidation_0-mlogloss:2.298553\n",
      "[140]\tvalidation_0-mlogloss:2.299212\n",
      "Stopping. Best iteration:\n",
      "[123]\tvalidation_0-mlogloss:2.298197\n",
      "\n",
      "max_depth - 5, min_child_weight - 5\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.083203\n",
      "[10]\tvalidation_0-mlogloss:2.431433\n",
      "[20]\tvalidation_0-mlogloss:2.347985\n",
      "[30]\tvalidation_0-mlogloss:2.324051\n",
      "[40]\tvalidation_0-mlogloss:2.314487\n",
      "[50]\tvalidation_0-mlogloss:2.308669\n",
      "[60]\tvalidation_0-mlogloss:2.303550\n",
      "[70]\tvalidation_0-mlogloss:2.301430\n",
      "[80]\tvalidation_0-mlogloss:2.298785\n",
      "[90]\tvalidation_0-mlogloss:2.297619\n",
      "[100]\tvalidation_0-mlogloss:2.296795\n",
      "[110]\tvalidation_0-mlogloss:2.296715\n",
      "[120]\tvalidation_0-mlogloss:2.296631\n",
      "Stopping. Best iteration:\n",
      "[107]\tvalidation_0-mlogloss:2.296444\n",
      "\n",
      "max_depth - 7, min_child_weight - 1\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.042867\n",
      "[10]\tvalidation_0-mlogloss:2.400256\n",
      "[20]\tvalidation_0-mlogloss:2.322299\n",
      "[30]\tvalidation_0-mlogloss:2.304362\n",
      "[40]\tvalidation_0-mlogloss:2.300490\n",
      "[50]\tvalidation_0-mlogloss:2.300059\n",
      "[60]\tvalidation_0-mlogloss:2.300231\n",
      "Stopping. Best iteration:\n",
      "[46]\tvalidation_0-mlogloss:2.299388\n",
      "\n",
      "max_depth - 7, min_child_weight - 3\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.043226\n",
      "[10]\tvalidation_0-mlogloss:2.402070\n",
      "[20]\tvalidation_0-mlogloss:2.324083\n",
      "[30]\tvalidation_0-mlogloss:2.307114\n",
      "[40]\tvalidation_0-mlogloss:2.301786\n",
      "[50]\tvalidation_0-mlogloss:2.298606\n",
      "[60]\tvalidation_0-mlogloss:2.297190\n",
      "[70]\tvalidation_0-mlogloss:2.297141\n",
      "[80]\tvalidation_0-mlogloss:2.299272\n",
      "Stopping. Best iteration:\n",
      "[64]\tvalidation_0-mlogloss:2.296548\n",
      "\n",
      "max_depth - 7, min_child_weight - 5\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.043399\n",
      "[10]\tvalidation_0-mlogloss:2.402948\n",
      "[20]\tvalidation_0-mlogloss:2.325043\n",
      "[30]\tvalidation_0-mlogloss:2.307293\n",
      "[40]\tvalidation_0-mlogloss:2.301295\n",
      "[50]\tvalidation_0-mlogloss:2.299103\n",
      "[60]\tvalidation_0-mlogloss:2.297843\n",
      "[70]\tvalidation_0-mlogloss:2.298241\n",
      "[80]\tvalidation_0-mlogloss:2.298871\n",
      "Stopping. Best iteration:\n",
      "[65]\tvalidation_0-mlogloss:2.297650\n",
      "\n",
      "max_depth - 9, min_child_weight - 1\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.029134\n",
      "[10]\tvalidation_0-mlogloss:2.394564\n",
      "[20]\tvalidation_0-mlogloss:2.323227\n",
      "[30]\tvalidation_0-mlogloss:2.314159\n",
      "[40]\tvalidation_0-mlogloss:2.316387\n",
      "Stopping. Best iteration:\n",
      "[29]\tvalidation_0-mlogloss:2.313935\n",
      "\n",
      "max_depth - 9, min_child_weight - 3\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.030058\n",
      "[10]\tvalidation_0-mlogloss:2.390929\n",
      "[20]\tvalidation_0-mlogloss:2.319394\n",
      "[30]\tvalidation_0-mlogloss:2.307484\n",
      "[40]\tvalidation_0-mlogloss:2.307182\n",
      "[50]\tvalidation_0-mlogloss:2.310601\n",
      "Stopping. Best iteration:\n",
      "[36]\tvalidation_0-mlogloss:2.305778\n",
      "\n",
      "max_depth - 9, min_child_weight - 5\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.029743\n",
      "[10]\tvalidation_0-mlogloss:2.391422\n",
      "[20]\tvalidation_0-mlogloss:2.319103\n",
      "[30]\tvalidation_0-mlogloss:2.306197\n",
      "[40]\tvalidation_0-mlogloss:2.304071\n",
      "[50]\tvalidation_0-mlogloss:2.305909\n",
      "Stopping. Best iteration:\n",
      "[37]\tvalidation_0-mlogloss:2.303449\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = pd.DataFrame(columns=['score', 'ntree', 'max_depth', 'min_child_weight'])\n",
    "for md in range(3,10,2):\n",
    "    for mcw in range(1,6,2):\n",
    "        sys.stderr.write('max_depth - {}, min_child_weight - {}\\n'.format(md, mcw))\n",
    "\n",
    "        model = MultiClassXGB(n_estimators=1000, learning_rate=0.3, max_depth=md, min_child_weight=mcw)\n",
    "        model.set_classes(y).set_eval(X_eval, y_eval, early_stopping_rounds=20)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        scores = scores.append({\n",
    "            'max_depth': md,\n",
    "            'min_child_weight': mcw,\n",
    "            'score': model.booster().best_score,\n",
    "            'ntree': model.booster().best_ntree_limit,\n",
    "        }, ignore_index=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>ntree</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.296444</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.296548</td>\n",
       "      <td>65</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.297650</td>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.298197</td>\n",
       "      <td>124</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.298693</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.299388</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.303111</td>\n",
       "      <td>332</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.303449</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.305653</td>\n",
       "      <td>277</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.305778</td>\n",
       "      <td>37</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.307324</td>\n",
       "      <td>298</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.313935</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score  ntree  max_depth  min_child_weight\n",
       "5   2.296444    108          5                 5\n",
       "7   2.296548     65          7                 3\n",
       "8   2.297650     66          7                 5\n",
       "4   2.298197    124          5                 3\n",
       "3   2.298693    108          5                 1\n",
       "6   2.299388     47          7                 1\n",
       "2   2.303111    332          3                 5\n",
       "11  2.303449     38          9                 5\n",
       "1   2.305653    277          3                 3\n",
       "10  2.305778     37          9                 3\n",
       "0   2.307324    298          3                 1\n",
       "9   2.313935     30          9                 1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.sort_values('score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_depth - 4, min_child_weight - 4\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.115974\n",
      "[10]\tvalidation_0-mlogloss:2.454088\n",
      "[20]\tvalidation_0-mlogloss:2.368408\n",
      "[30]\tvalidation_0-mlogloss:2.344609\n",
      "[40]\tvalidation_0-mlogloss:2.332618\n",
      "[50]\tvalidation_0-mlogloss:2.323309\n",
      "[60]\tvalidation_0-mlogloss:2.317970\n",
      "[70]\tvalidation_0-mlogloss:2.314027\n",
      "[80]\tvalidation_0-mlogloss:2.309987\n",
      "[90]\tvalidation_0-mlogloss:2.306998\n",
      "[100]\tvalidation_0-mlogloss:2.304510\n",
      "[110]\tvalidation_0-mlogloss:2.302484\n",
      "[120]\tvalidation_0-mlogloss:2.301468\n",
      "[130]\tvalidation_0-mlogloss:2.300224\n",
      "[140]\tvalidation_0-mlogloss:2.299592\n",
      "[150]\tvalidation_0-mlogloss:2.299006\n",
      "[160]\tvalidation_0-mlogloss:2.298937\n",
      "[170]\tvalidation_0-mlogloss:2.298474\n",
      "[180]\tvalidation_0-mlogloss:2.298251\n",
      "[190]\tvalidation_0-mlogloss:2.298431\n",
      "[200]\tvalidation_0-mlogloss:2.298880\n",
      "Stopping. Best iteration:\n",
      "[182]\tvalidation_0-mlogloss:2.298124\n",
      "\n",
      "max_depth - 4, min_child_weight - 5\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.116141\n",
      "[10]\tvalidation_0-mlogloss:2.455148\n",
      "[20]\tvalidation_0-mlogloss:2.369778\n",
      "[30]\tvalidation_0-mlogloss:2.344908\n",
      "[40]\tvalidation_0-mlogloss:2.330973\n",
      "[50]\tvalidation_0-mlogloss:2.323069\n",
      "[60]\tvalidation_0-mlogloss:2.317666\n",
      "[70]\tvalidation_0-mlogloss:2.313030\n",
      "[80]\tvalidation_0-mlogloss:2.309614\n",
      "[90]\tvalidation_0-mlogloss:2.307099\n",
      "[100]\tvalidation_0-mlogloss:2.305061\n",
      "[110]\tvalidation_0-mlogloss:2.302896\n",
      "[120]\tvalidation_0-mlogloss:2.301808\n",
      "[130]\tvalidation_0-mlogloss:2.301349\n",
      "[140]\tvalidation_0-mlogloss:2.300860\n",
      "[150]\tvalidation_0-mlogloss:2.300287\n",
      "[160]\tvalidation_0-mlogloss:2.299932\n",
      "[170]\tvalidation_0-mlogloss:2.299615\n",
      "[180]\tvalidation_0-mlogloss:2.298983\n",
      "[190]\tvalidation_0-mlogloss:2.299153\n",
      "[200]\tvalidation_0-mlogloss:2.299327\n",
      "Stopping. Best iteration:\n",
      "[187]\tvalidation_0-mlogloss:2.298814\n",
      "\n",
      "max_depth - 4, min_child_weight - 6\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.116039\n",
      "[10]\tvalidation_0-mlogloss:2.453741\n",
      "[20]\tvalidation_0-mlogloss:2.367188\n",
      "[30]\tvalidation_0-mlogloss:2.343193\n",
      "[40]\tvalidation_0-mlogloss:2.331926\n",
      "[50]\tvalidation_0-mlogloss:2.323273\n",
      "[60]\tvalidation_0-mlogloss:2.316263\n",
      "[70]\tvalidation_0-mlogloss:2.313148\n",
      "[80]\tvalidation_0-mlogloss:2.309484\n",
      "[90]\tvalidation_0-mlogloss:2.307075\n",
      "[100]\tvalidation_0-mlogloss:2.304804\n",
      "[110]\tvalidation_0-mlogloss:2.303456\n",
      "[120]\tvalidation_0-mlogloss:2.301905\n",
      "[130]\tvalidation_0-mlogloss:2.300811\n",
      "[140]\tvalidation_0-mlogloss:2.300187\n",
      "[150]\tvalidation_0-mlogloss:2.299065\n",
      "[160]\tvalidation_0-mlogloss:2.298682\n",
      "[170]\tvalidation_0-mlogloss:2.298283\n",
      "[180]\tvalidation_0-mlogloss:2.298451\n",
      "[190]\tvalidation_0-mlogloss:2.298592\n",
      "Stopping. Best iteration:\n",
      "[170]\tvalidation_0-mlogloss:2.298283\n",
      "\n",
      "max_depth - 5, min_child_weight - 4\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.083005\n",
      "[10]\tvalidation_0-mlogloss:2.431480\n",
      "[20]\tvalidation_0-mlogloss:2.348222\n",
      "[30]\tvalidation_0-mlogloss:2.325052\n",
      "[40]\tvalidation_0-mlogloss:2.314562\n",
      "[50]\tvalidation_0-mlogloss:2.309859\n",
      "[60]\tvalidation_0-mlogloss:2.306876\n",
      "[70]\tvalidation_0-mlogloss:2.303326\n",
      "[80]\tvalidation_0-mlogloss:2.300317\n",
      "[90]\tvalidation_0-mlogloss:2.298653\n",
      "[100]\tvalidation_0-mlogloss:2.298156\n",
      "[110]\tvalidation_0-mlogloss:2.297692\n",
      "[120]\tvalidation_0-mlogloss:2.297890\n",
      "Stopping. Best iteration:\n",
      "[109]\tvalidation_0-mlogloss:2.297668\n",
      "\n",
      "max_depth - 5, min_child_weight - 5\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.083203\n",
      "[10]\tvalidation_0-mlogloss:2.431433\n",
      "[20]\tvalidation_0-mlogloss:2.347985\n",
      "[30]\tvalidation_0-mlogloss:2.324051\n",
      "[40]\tvalidation_0-mlogloss:2.314487\n",
      "[50]\tvalidation_0-mlogloss:2.308669\n",
      "[60]\tvalidation_0-mlogloss:2.303550\n",
      "[70]\tvalidation_0-mlogloss:2.301430\n",
      "[80]\tvalidation_0-mlogloss:2.298785\n",
      "[90]\tvalidation_0-mlogloss:2.297619\n",
      "[100]\tvalidation_0-mlogloss:2.296795\n",
      "[110]\tvalidation_0-mlogloss:2.296715\n",
      "[120]\tvalidation_0-mlogloss:2.296631\n",
      "Stopping. Best iteration:\n",
      "[107]\tvalidation_0-mlogloss:2.296444\n",
      "\n",
      "max_depth - 5, min_child_weight - 6\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.083761\n",
      "[10]\tvalidation_0-mlogloss:2.431456\n",
      "[20]\tvalidation_0-mlogloss:2.349110\n",
      "[30]\tvalidation_0-mlogloss:2.326177\n",
      "[40]\tvalidation_0-mlogloss:2.316223\n",
      "[50]\tvalidation_0-mlogloss:2.310526\n",
      "[60]\tvalidation_0-mlogloss:2.304614\n",
      "[70]\tvalidation_0-mlogloss:2.301925\n",
      "[80]\tvalidation_0-mlogloss:2.299301\n",
      "[90]\tvalidation_0-mlogloss:2.298055\n",
      "[100]\tvalidation_0-mlogloss:2.296850\n",
      "[110]\tvalidation_0-mlogloss:2.296040\n",
      "[120]\tvalidation_0-mlogloss:2.295649\n",
      "[130]\tvalidation_0-mlogloss:2.296420\n",
      "[140]\tvalidation_0-mlogloss:2.296288\n",
      "Stopping. Best iteration:\n",
      "[120]\tvalidation_0-mlogloss:2.295649\n",
      "\n",
      "max_depth - 6, min_child_weight - 4\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.060856\n",
      "[10]\tvalidation_0-mlogloss:2.412197\n",
      "[20]\tvalidation_0-mlogloss:2.334061\n",
      "[30]\tvalidation_0-mlogloss:2.314794\n",
      "[40]\tvalidation_0-mlogloss:2.306293\n",
      "[50]\tvalidation_0-mlogloss:2.301818\n",
      "[60]\tvalidation_0-mlogloss:2.299570\n",
      "[70]\tvalidation_0-mlogloss:2.297438\n",
      "[80]\tvalidation_0-mlogloss:2.296469\n",
      "[90]\tvalidation_0-mlogloss:2.297610\n",
      "Stopping. Best iteration:\n",
      "[78]\tvalidation_0-mlogloss:2.296353\n",
      "\n",
      "max_depth - 6, min_child_weight - 5\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.061784\n",
      "[10]\tvalidation_0-mlogloss:2.413942\n",
      "[20]\tvalidation_0-mlogloss:2.333930\n",
      "[30]\tvalidation_0-mlogloss:2.313497\n",
      "[40]\tvalidation_0-mlogloss:2.305408\n",
      "[50]\tvalidation_0-mlogloss:2.300625\n",
      "[60]\tvalidation_0-mlogloss:2.297026\n",
      "[70]\tvalidation_0-mlogloss:2.295637\n",
      "[80]\tvalidation_0-mlogloss:2.295459\n",
      "[90]\tvalidation_0-mlogloss:2.295947\n",
      "Stopping. Best iteration:\n",
      "[79]\tvalidation_0-mlogloss:2.295266\n",
      "\n",
      "max_depth - 6, min_child_weight - 6\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.062618\n",
      "[10]\tvalidation_0-mlogloss:2.414852\n",
      "[20]\tvalidation_0-mlogloss:2.336042\n",
      "[30]\tvalidation_0-mlogloss:2.315436\n",
      "[40]\tvalidation_0-mlogloss:2.306682\n",
      "[50]\tvalidation_0-mlogloss:2.301660\n",
      "[60]\tvalidation_0-mlogloss:2.298510\n",
      "[70]\tvalidation_0-mlogloss:2.296957\n",
      "[80]\tvalidation_0-mlogloss:2.296214\n",
      "[90]\tvalidation_0-mlogloss:2.296327\n",
      "Stopping. Best iteration:\n",
      "[77]\tvalidation_0-mlogloss:2.296003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores2 = pd.DataFrame(columns=['score', 'ntree', 'max_depth', 'min_child_weight'])\n",
    "for md in [4, 5, 6]:\n",
    "    for mcw in [4, 5, 6]:\n",
    "        sys.stderr.write('max_depth - {}, min_child_weight - {}\\n'.format(md, mcw))\n",
    "\n",
    "        model = MultiClassXGB(n_estimators=1000, learning_rate=0.3, max_depth=md, min_child_weight=mcw)\n",
    "        model.set_classes(y).set_eval(X_eval, y_eval, early_stopping_rounds=20)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        scores2 = scores2.append({\n",
    "            'max_depth': md,\n",
    "            'min_child_weight': mcw,\n",
    "            'score': model.booster().best_score,\n",
    "            'ntree': model.booster().best_ntree_limit,\n",
    "        }, ignore_index=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>ntree</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.295266</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.295649</td>\n",
       "      <td>121</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.296003</td>\n",
       "      <td>78</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.296353</td>\n",
       "      <td>79</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.296444</td>\n",
       "      <td>108</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.297668</td>\n",
       "      <td>110</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.298124</td>\n",
       "      <td>183</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.298283</td>\n",
       "      <td>171</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.298814</td>\n",
       "      <td>188</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  ntree  max_depth  min_child_weight\n",
       "7  2.295266     80          6                 5\n",
       "5  2.295649    121          5                 6\n",
       "8  2.296003     78          6                 6\n",
       "6  2.296353     79          6                 4\n",
       "4  2.296444    108          5                 5\n",
       "3  2.297668    110          5                 4\n",
       "0  2.298124    183          4                 4\n",
       "2  2.298283    171          4                 6\n",
       "1  2.298814    188          4                 5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores2.sort_values('score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gamma - 0.0\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.061784\n",
      "[10]\tvalidation_0-mlogloss:2.413942\n",
      "[20]\tvalidation_0-mlogloss:2.333930\n",
      "[30]\tvalidation_0-mlogloss:2.313497\n",
      "[40]\tvalidation_0-mlogloss:2.305408\n",
      "[50]\tvalidation_0-mlogloss:2.300625\n",
      "[60]\tvalidation_0-mlogloss:2.297026\n",
      "[70]\tvalidation_0-mlogloss:2.295637\n",
      "[80]\tvalidation_0-mlogloss:2.295459\n",
      "[90]\tvalidation_0-mlogloss:2.295947\n",
      "Stopping. Best iteration:\n",
      "[79]\tvalidation_0-mlogloss:2.295266\n",
      "\n",
      "gamma - 0.1\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.061774\n",
      "[10]\tvalidation_0-mlogloss:2.414263\n",
      "[20]\tvalidation_0-mlogloss:2.335211\n",
      "[30]\tvalidation_0-mlogloss:2.314187\n",
      "[40]\tvalidation_0-mlogloss:2.306344\n",
      "[50]\tvalidation_0-mlogloss:2.301806\n",
      "[60]\tvalidation_0-mlogloss:2.299371\n",
      "[70]\tvalidation_0-mlogloss:2.297033\n",
      "[80]\tvalidation_0-mlogloss:2.295794\n",
      "[90]\tvalidation_0-mlogloss:2.295661\n",
      "[100]\tvalidation_0-mlogloss:2.295973\n",
      "[110]\tvalidation_0-mlogloss:2.296464\n",
      "Stopping. Best iteration:\n",
      "[90]\tvalidation_0-mlogloss:2.295661\n",
      "\n",
      "gamma - 0.2\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.061772\n",
      "[10]\tvalidation_0-mlogloss:2.413726\n",
      "[20]\tvalidation_0-mlogloss:2.334742\n",
      "[30]\tvalidation_0-mlogloss:2.314051\n",
      "[40]\tvalidation_0-mlogloss:2.305803\n",
      "[50]\tvalidation_0-mlogloss:2.300239\n",
      "[60]\tvalidation_0-mlogloss:2.297750\n",
      "[70]\tvalidation_0-mlogloss:2.296609\n",
      "[80]\tvalidation_0-mlogloss:2.295670\n",
      "[90]\tvalidation_0-mlogloss:2.296076\n",
      "[100]\tvalidation_0-mlogloss:2.296936\n",
      "Stopping. Best iteration:\n",
      "[84]\tvalidation_0-mlogloss:2.295428\n",
      "\n",
      "gamma - 0.3\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.061766\n",
      "[10]\tvalidation_0-mlogloss:2.414607\n",
      "[20]\tvalidation_0-mlogloss:2.334000\n",
      "[30]\tvalidation_0-mlogloss:2.314877\n",
      "[40]\tvalidation_0-mlogloss:2.306542\n",
      "[50]\tvalidation_0-mlogloss:2.300530\n",
      "[60]\tvalidation_0-mlogloss:2.297604\n",
      "[70]\tvalidation_0-mlogloss:2.296652\n",
      "[80]\tvalidation_0-mlogloss:2.295096\n",
      "[90]\tvalidation_0-mlogloss:2.295703\n",
      "[100]\tvalidation_0-mlogloss:2.296055\n",
      "Stopping. Best iteration:\n",
      "[81]\tvalidation_0-mlogloss:2.295007\n",
      "\n",
      "gamma - 0.4\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.061764\n",
      "[10]\tvalidation_0-mlogloss:2.414030\n",
      "[20]\tvalidation_0-mlogloss:2.335714\n",
      "[30]\tvalidation_0-mlogloss:2.314391\n",
      "[40]\tvalidation_0-mlogloss:2.305307\n",
      "[50]\tvalidation_0-mlogloss:2.301701\n",
      "[60]\tvalidation_0-mlogloss:2.297685\n",
      "[70]\tvalidation_0-mlogloss:2.295920\n",
      "[80]\tvalidation_0-mlogloss:2.294401\n",
      "[90]\tvalidation_0-mlogloss:2.293968\n",
      "[100]\tvalidation_0-mlogloss:2.294407\n",
      "[110]\tvalidation_0-mlogloss:2.295005\n",
      "Stopping. Best iteration:\n",
      "[92]\tvalidation_0-mlogloss:2.293897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores3 = pd.DataFrame(columns=['score', 'ntree', 'gamma'])\n",
    "for g in [i/10.0 for i in range(0,5)]:\n",
    "    sys.stderr.write('gamma - {}\\n'.format(g))\n",
    "\n",
    "    model = MultiClassXGB(n_estimators=1000, learning_rate=0.3, max_depth=6, min_child_weight=5, gamma=g)\n",
    "    model.set_classes(y).set_eval(X_eval, y_eval, early_stopping_rounds=20)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    scores3 = scores3.append({\n",
    "        'gamma': g,\n",
    "        'score': model.booster().best_score,\n",
    "        'ntree': model.booster().best_ntree_limit,\n",
    "    }, ignore_index=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>ntree</th>\n",
       "      <th>gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.293897</td>\n",
       "      <td>93</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.295007</td>\n",
       "      <td>82</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.295266</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.295428</td>\n",
       "      <td>85</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.295661</td>\n",
       "      <td>91</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  ntree  gamma\n",
       "4  2.293897     93    0.4\n",
       "3  2.295007     82    0.3\n",
       "0  2.295266     80    0.0\n",
       "2  2.295428     85    0.2\n",
       "1  2.295661     91    0.1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores3.sort_values('score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gamma - 0.45\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.061753\n",
      "[10]\tvalidation_0-mlogloss:2.413977\n",
      "[20]\tvalidation_0-mlogloss:2.335418\n",
      "[30]\tvalidation_0-mlogloss:2.314186\n",
      "[40]\tvalidation_0-mlogloss:2.306959\n",
      "[50]\tvalidation_0-mlogloss:2.302511\n",
      "[60]\tvalidation_0-mlogloss:2.299978\n",
      "[70]\tvalidation_0-mlogloss:2.298564\n",
      "[80]\tvalidation_0-mlogloss:2.297459\n",
      "[90]\tvalidation_0-mlogloss:2.298101\n",
      "[100]\tvalidation_0-mlogloss:2.297940\n",
      "Stopping. Best iteration:\n",
      "[82]\tvalidation_0-mlogloss:2.297388\n",
      "\n",
      "gamma - 0.5\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.061750\n",
      "[10]\tvalidation_0-mlogloss:2.414466\n",
      "[20]\tvalidation_0-mlogloss:2.335747\n",
      "[30]\tvalidation_0-mlogloss:2.317085\n",
      "[40]\tvalidation_0-mlogloss:2.308886\n",
      "[50]\tvalidation_0-mlogloss:2.303692\n",
      "[60]\tvalidation_0-mlogloss:2.299880\n",
      "[70]\tvalidation_0-mlogloss:2.298175\n",
      "[80]\tvalidation_0-mlogloss:2.296424\n",
      "[90]\tvalidation_0-mlogloss:2.295641\n",
      "[100]\tvalidation_0-mlogloss:2.296324\n",
      "[110]\tvalidation_0-mlogloss:2.296289\n",
      "Stopping. Best iteration:\n",
      "[95]\tvalidation_0-mlogloss:2.295502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores4 = pd.DataFrame(columns=['score', 'ntree', 'gamma'])\n",
    "for g in [0.45, 0.5]:\n",
    "    sys.stderr.write('gamma - {}\\n'.format(g))\n",
    "\n",
    "    model = MultiClassXGB(n_estimators=1000, learning_rate=0.3, max_depth=6, min_child_weight=5, gamma=g)\n",
    "    model.set_classes(y).set_eval(X_eval, y_eval, early_stopping_rounds=20)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    scores4 = scores4.append({\n",
    "        'gamma': g,\n",
    "        'score': model.booster().best_score,\n",
    "        'ntree': model.booster().best_ntree_limit,\n",
    "    }, ignore_index=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>ntree</th>\n",
       "      <th>gamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.295502</td>\n",
       "      <td>96</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.297388</td>\n",
       "      <td>83</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  ntree  gamma\n",
       "1  2.295502     96   0.50\n",
       "0  2.297388     83   0.45"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores4.sort_values('score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "subsample - 0.6, colsample_bytree - 0.6\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.126597\n",
      "[10]\tvalidation_0-mlogloss:2.425286\n",
      "[20]\tvalidation_0-mlogloss:2.340758\n",
      "[30]\tvalidation_0-mlogloss:2.318621\n",
      "[40]\tvalidation_0-mlogloss:2.309615\n",
      "[50]\tvalidation_0-mlogloss:2.306844\n",
      "[60]\tvalidation_0-mlogloss:2.305323\n",
      "[70]\tvalidation_0-mlogloss:2.304673\n",
      "[80]\tvalidation_0-mlogloss:2.304798\n",
      "[90]\tvalidation_0-mlogloss:2.306337\n",
      "Stopping. Best iteration:\n",
      "[72]\tvalidation_0-mlogloss:2.304605\n",
      "\n",
      "subsample - 0.6, colsample_bytree - 0.7\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.124648\n",
      "[10]\tvalidation_0-mlogloss:2.424572\n",
      "[20]\tvalidation_0-mlogloss:2.339721\n",
      "[30]\tvalidation_0-mlogloss:2.319628\n",
      "[40]\tvalidation_0-mlogloss:2.311095\n",
      "[50]\tvalidation_0-mlogloss:2.307867\n",
      "[60]\tvalidation_0-mlogloss:2.306843\n",
      "[70]\tvalidation_0-mlogloss:2.306996\n",
      "[80]\tvalidation_0-mlogloss:2.307806\n",
      "Stopping. Best iteration:\n",
      "[63]\tvalidation_0-mlogloss:2.306458\n",
      "\n",
      "subsample - 0.6, colsample_bytree - 0.8\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.100878\n",
      "[10]\tvalidation_0-mlogloss:2.422165\n",
      "[20]\tvalidation_0-mlogloss:2.340243\n",
      "[30]\tvalidation_0-mlogloss:2.319421\n",
      "[40]\tvalidation_0-mlogloss:2.309992\n",
      "[50]\tvalidation_0-mlogloss:2.307082\n",
      "[60]\tvalidation_0-mlogloss:2.306120\n",
      "[70]\tvalidation_0-mlogloss:2.305628\n",
      "[80]\tvalidation_0-mlogloss:2.305230\n",
      "[90]\tvalidation_0-mlogloss:2.306913\n",
      "Stopping. Best iteration:\n",
      "[79]\tvalidation_0-mlogloss:2.305092\n",
      "\n",
      "subsample - 0.6, colsample_bytree - 0.9\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.098707\n",
      "[10]\tvalidation_0-mlogloss:2.418088\n",
      "[20]\tvalidation_0-mlogloss:2.338215\n",
      "[30]\tvalidation_0-mlogloss:2.319715\n",
      "[40]\tvalidation_0-mlogloss:2.311289\n",
      "[50]\tvalidation_0-mlogloss:2.307238\n",
      "[60]\tvalidation_0-mlogloss:2.306334\n",
      "[70]\tvalidation_0-mlogloss:2.306382\n",
      "[80]\tvalidation_0-mlogloss:2.307686\n",
      "Stopping. Best iteration:\n",
      "[62]\tvalidation_0-mlogloss:2.306016\n",
      "\n",
      "subsample - 0.6, colsample_bytree - 1.0\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.068056\n",
      "[10]\tvalidation_0-mlogloss:2.419457\n",
      "[20]\tvalidation_0-mlogloss:2.341287\n",
      "[30]\tvalidation_0-mlogloss:2.322773\n",
      "[40]\tvalidation_0-mlogloss:2.314936\n",
      "[50]\tvalidation_0-mlogloss:2.310939\n",
      "[60]\tvalidation_0-mlogloss:2.310131\n",
      "[70]\tvalidation_0-mlogloss:2.310138\n",
      "Stopping. Best iteration:\n",
      "[58]\tvalidation_0-mlogloss:2.309997\n",
      "\n",
      "subsample - 0.7, colsample_bytree - 0.6\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.126395\n",
      "[10]\tvalidation_0-mlogloss:2.423929\n",
      "[20]\tvalidation_0-mlogloss:2.339523\n",
      "[30]\tvalidation_0-mlogloss:2.316560\n",
      "[40]\tvalidation_0-mlogloss:2.307260\n",
      "[50]\tvalidation_0-mlogloss:2.304299\n",
      "[60]\tvalidation_0-mlogloss:2.302320\n",
      "[70]\tvalidation_0-mlogloss:2.301121\n",
      "[80]\tvalidation_0-mlogloss:2.300265\n",
      "[90]\tvalidation_0-mlogloss:2.300904\n",
      "Stopping. Best iteration:\n",
      "[79]\tvalidation_0-mlogloss:2.300011\n",
      "\n",
      "subsample - 0.7, colsample_bytree - 0.7\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.125252\n",
      "[10]\tvalidation_0-mlogloss:2.421374\n",
      "[20]\tvalidation_0-mlogloss:2.337963\n",
      "[30]\tvalidation_0-mlogloss:2.317269\n",
      "[40]\tvalidation_0-mlogloss:2.307817\n",
      "[50]\tvalidation_0-mlogloss:2.304394\n",
      "[60]\tvalidation_0-mlogloss:2.302539\n",
      "[70]\tvalidation_0-mlogloss:2.301904\n",
      "[80]\tvalidation_0-mlogloss:2.301461\n",
      "[90]\tvalidation_0-mlogloss:2.301983\n",
      "Stopping. Best iteration:\n",
      "[79]\tvalidation_0-mlogloss:2.301362\n",
      "\n",
      "subsample - 0.7, colsample_bytree - 0.8\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.102753\n",
      "[10]\tvalidation_0-mlogloss:2.420687\n",
      "[20]\tvalidation_0-mlogloss:2.339019\n",
      "[30]\tvalidation_0-mlogloss:2.317928\n",
      "[40]\tvalidation_0-mlogloss:2.309084\n",
      "[50]\tvalidation_0-mlogloss:2.306122\n",
      "[60]\tvalidation_0-mlogloss:2.303625\n",
      "[70]\tvalidation_0-mlogloss:2.302108\n",
      "[80]\tvalidation_0-mlogloss:2.302211\n",
      "[90]\tvalidation_0-mlogloss:2.303857\n",
      "Stopping. Best iteration:\n",
      "[72]\tvalidation_0-mlogloss:2.301989\n",
      "\n",
      "subsample - 0.7, colsample_bytree - 0.9\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.099173\n",
      "[10]\tvalidation_0-mlogloss:2.414618\n",
      "[20]\tvalidation_0-mlogloss:2.334949\n",
      "[30]\tvalidation_0-mlogloss:2.314796\n",
      "[40]\tvalidation_0-mlogloss:2.307439\n",
      "[50]\tvalidation_0-mlogloss:2.305035\n",
      "[60]\tvalidation_0-mlogloss:2.303358\n",
      "[70]\tvalidation_0-mlogloss:2.303082\n",
      "[80]\tvalidation_0-mlogloss:2.303196\n",
      "Stopping. Best iteration:\n",
      "[63]\tvalidation_0-mlogloss:2.302795\n",
      "\n",
      "subsample - 0.7, colsample_bytree - 1.0\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.064557\n",
      "[10]\tvalidation_0-mlogloss:2.416278\n",
      "[20]\tvalidation_0-mlogloss:2.337891\n",
      "[30]\tvalidation_0-mlogloss:2.318720\n",
      "[40]\tvalidation_0-mlogloss:2.310664\n",
      "[50]\tvalidation_0-mlogloss:2.307436\n",
      "[60]\tvalidation_0-mlogloss:2.305110\n",
      "[70]\tvalidation_0-mlogloss:2.305129\n",
      "[80]\tvalidation_0-mlogloss:2.305505\n",
      "Stopping. Best iteration:\n",
      "[61]\tvalidation_0-mlogloss:2.304997\n",
      "\n",
      "subsample - 0.8, colsample_bytree - 0.6\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.125321\n",
      "[10]\tvalidation_0-mlogloss:2.421662\n",
      "[20]\tvalidation_0-mlogloss:2.336607\n",
      "[30]\tvalidation_0-mlogloss:2.315110\n",
      "[40]\tvalidation_0-mlogloss:2.306164\n",
      "[50]\tvalidation_0-mlogloss:2.301762\n",
      "[60]\tvalidation_0-mlogloss:2.297729\n",
      "[70]\tvalidation_0-mlogloss:2.297812\n",
      "[80]\tvalidation_0-mlogloss:2.296905\n",
      "[90]\tvalidation_0-mlogloss:2.297419\n",
      "Stopping. Best iteration:\n",
      "[79]\tvalidation_0-mlogloss:2.296692\n",
      "\n",
      "subsample - 0.8, colsample_bytree - 0.7\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.123586\n",
      "[10]\tvalidation_0-mlogloss:2.417880\n",
      "[20]\tvalidation_0-mlogloss:2.334347\n",
      "[30]\tvalidation_0-mlogloss:2.313381\n",
      "[40]\tvalidation_0-mlogloss:2.305026\n",
      "[50]\tvalidation_0-mlogloss:2.301539\n",
      "[60]\tvalidation_0-mlogloss:2.298631\n",
      "[70]\tvalidation_0-mlogloss:2.297920\n",
      "[80]\tvalidation_0-mlogloss:2.298080\n",
      "Stopping. Best iteration:\n",
      "[68]\tvalidation_0-mlogloss:2.297657\n",
      "\n",
      "subsample - 0.8, colsample_bytree - 0.8\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.100537\n",
      "[10]\tvalidation_0-mlogloss:2.416854\n",
      "[20]\tvalidation_0-mlogloss:2.334948\n",
      "[30]\tvalidation_0-mlogloss:2.314538\n",
      "[40]\tvalidation_0-mlogloss:2.305133\n",
      "[50]\tvalidation_0-mlogloss:2.301680\n",
      "[60]\tvalidation_0-mlogloss:2.298218\n",
      "[70]\tvalidation_0-mlogloss:2.297935\n",
      "[80]\tvalidation_0-mlogloss:2.297836\n",
      "[90]\tvalidation_0-mlogloss:2.298132\n",
      "Stopping. Best iteration:\n",
      "[79]\tvalidation_0-mlogloss:2.297521\n",
      "\n",
      "subsample - 0.8, colsample_bytree - 0.9\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.098627\n",
      "[10]\tvalidation_0-mlogloss:2.415139\n",
      "[20]\tvalidation_0-mlogloss:2.334255\n",
      "[30]\tvalidation_0-mlogloss:2.314692\n",
      "[40]\tvalidation_0-mlogloss:2.305639\n",
      "[50]\tvalidation_0-mlogloss:2.302387\n",
      "[60]\tvalidation_0-mlogloss:2.300575\n",
      "[70]\tvalidation_0-mlogloss:2.299525\n",
      "[80]\tvalidation_0-mlogloss:2.299992\n",
      "[90]\tvalidation_0-mlogloss:2.301691\n",
      "Stopping. Best iteration:\n",
      "[72]\tvalidation_0-mlogloss:2.299277\n",
      "\n",
      "subsample - 0.8, colsample_bytree - 1.0\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.062605\n",
      "[10]\tvalidation_0-mlogloss:2.413823\n",
      "[20]\tvalidation_0-mlogloss:2.334172\n",
      "[30]\tvalidation_0-mlogloss:2.312998\n",
      "[40]\tvalidation_0-mlogloss:2.304969\n",
      "[50]\tvalidation_0-mlogloss:2.300871\n",
      "[60]\tvalidation_0-mlogloss:2.298450\n",
      "[70]\tvalidation_0-mlogloss:2.298117\n",
      "[80]\tvalidation_0-mlogloss:2.297763\n",
      "[90]\tvalidation_0-mlogloss:2.299577\n",
      "Stopping. Best iteration:\n",
      "[77]\tvalidation_0-mlogloss:2.297590\n",
      "\n",
      "subsample - 0.9, colsample_bytree - 0.6\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.123463\n",
      "[10]\tvalidation_0-mlogloss:2.419594\n",
      "[20]\tvalidation_0-mlogloss:2.335390\n",
      "[30]\tvalidation_0-mlogloss:2.313653\n",
      "[40]\tvalidation_0-mlogloss:2.304622\n",
      "[50]\tvalidation_0-mlogloss:2.300396\n",
      "[60]\tvalidation_0-mlogloss:2.297127\n",
      "[70]\tvalidation_0-mlogloss:2.294509\n",
      "[80]\tvalidation_0-mlogloss:2.293791\n",
      "[90]\tvalidation_0-mlogloss:2.293269\n",
      "[100]\tvalidation_0-mlogloss:2.292999\n",
      "[110]\tvalidation_0-mlogloss:2.294228\n",
      "Stopping. Best iteration:\n",
      "[92]\tvalidation_0-mlogloss:2.292894\n",
      "\n",
      "subsample - 0.9, colsample_bytree - 0.7\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.121226\n",
      "[10]\tvalidation_0-mlogloss:2.416690\n",
      "[20]\tvalidation_0-mlogloss:2.332785\n",
      "[30]\tvalidation_0-mlogloss:2.311258\n",
      "[40]\tvalidation_0-mlogloss:2.303328\n",
      "[50]\tvalidation_0-mlogloss:2.297771\n",
      "[60]\tvalidation_0-mlogloss:2.294584\n",
      "[70]\tvalidation_0-mlogloss:2.294308\n",
      "[80]\tvalidation_0-mlogloss:2.293485\n",
      "[90]\tvalidation_0-mlogloss:2.294129\n",
      "Stopping. Best iteration:\n",
      "[79]\tvalidation_0-mlogloss:2.293443\n",
      "\n",
      "subsample - 0.9, colsample_bytree - 0.8\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.097211\n",
      "[10]\tvalidation_0-mlogloss:2.416324\n",
      "[20]\tvalidation_0-mlogloss:2.334618\n",
      "[30]\tvalidation_0-mlogloss:2.313839\n",
      "[40]\tvalidation_0-mlogloss:2.305159\n",
      "[50]\tvalidation_0-mlogloss:2.300666\n",
      "[60]\tvalidation_0-mlogloss:2.298144\n",
      "[70]\tvalidation_0-mlogloss:2.295868\n",
      "[80]\tvalidation_0-mlogloss:2.295052\n",
      "[90]\tvalidation_0-mlogloss:2.294709\n",
      "[100]\tvalidation_0-mlogloss:2.294962\n",
      "[110]\tvalidation_0-mlogloss:2.295755\n",
      "Stopping. Best iteration:\n",
      "[97]\tvalidation_0-mlogloss:2.294567\n",
      "\n",
      "subsample - 0.9, colsample_bytree - 0.9\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.097496\n",
      "[10]\tvalidation_0-mlogloss:2.413733\n",
      "[20]\tvalidation_0-mlogloss:2.333630\n",
      "[30]\tvalidation_0-mlogloss:2.314068\n",
      "[40]\tvalidation_0-mlogloss:2.305054\n",
      "[50]\tvalidation_0-mlogloss:2.300501\n",
      "[60]\tvalidation_0-mlogloss:2.296970\n",
      "[70]\tvalidation_0-mlogloss:2.295817\n",
      "[80]\tvalidation_0-mlogloss:2.295099\n",
      "[90]\tvalidation_0-mlogloss:2.295090\n",
      "Stopping. Best iteration:\n",
      "[78]\tvalidation_0-mlogloss:2.294578\n",
      "\n",
      "subsample - 0.9, colsample_bytree - 1.0\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.060216\n",
      "[10]\tvalidation_0-mlogloss:2.413050\n",
      "[20]\tvalidation_0-mlogloss:2.334310\n",
      "[30]\tvalidation_0-mlogloss:2.315075\n",
      "[40]\tvalidation_0-mlogloss:2.306997\n",
      "[50]\tvalidation_0-mlogloss:2.301714\n",
      "[60]\tvalidation_0-mlogloss:2.299093\n",
      "[70]\tvalidation_0-mlogloss:2.298745\n",
      "[80]\tvalidation_0-mlogloss:2.297887\n",
      "[90]\tvalidation_0-mlogloss:2.297871\n",
      "[100]\tvalidation_0-mlogloss:2.299359\n",
      "Stopping. Best iteration:\n",
      "[85]\tvalidation_0-mlogloss:2.297379\n",
      "\n",
      "subsample - 1.0, colsample_bytree - 0.6\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.103382\n",
      "[10]\tvalidation_0-mlogloss:2.416899\n",
      "[20]\tvalidation_0-mlogloss:2.333320\n",
      "[30]\tvalidation_0-mlogloss:2.311936\n",
      "[40]\tvalidation_0-mlogloss:2.304623\n",
      "[50]\tvalidation_0-mlogloss:2.299737\n",
      "[60]\tvalidation_0-mlogloss:2.296763\n",
      "[70]\tvalidation_0-mlogloss:2.295046\n",
      "[80]\tvalidation_0-mlogloss:2.292320\n",
      "[90]\tvalidation_0-mlogloss:2.292622\n",
      "[100]\tvalidation_0-mlogloss:2.292734\n",
      "Stopping. Best iteration:\n",
      "[81]\tvalidation_0-mlogloss:2.292213\n",
      "\n",
      "subsample - 1.0, colsample_bytree - 0.7\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.095984\n",
      "[10]\tvalidation_0-mlogloss:2.413413\n",
      "[20]\tvalidation_0-mlogloss:2.333016\n",
      "[30]\tvalidation_0-mlogloss:2.312036\n",
      "[40]\tvalidation_0-mlogloss:2.305081\n",
      "[50]\tvalidation_0-mlogloss:2.299777\n",
      "[60]\tvalidation_0-mlogloss:2.295870\n",
      "[70]\tvalidation_0-mlogloss:2.293725\n",
      "[80]\tvalidation_0-mlogloss:2.292590\n",
      "[90]\tvalidation_0-mlogloss:2.292814\n",
      "[100]\tvalidation_0-mlogloss:2.292902\n",
      "Stopping. Best iteration:\n",
      "[86]\tvalidation_0-mlogloss:2.292366\n",
      "\n",
      "subsample - 1.0, colsample_bytree - 0.8\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.084105\n",
      "[10]\tvalidation_0-mlogloss:2.409492\n",
      "[20]\tvalidation_0-mlogloss:2.329248\n",
      "[30]\tvalidation_0-mlogloss:2.309435\n",
      "[40]\tvalidation_0-mlogloss:2.301132\n",
      "[50]\tvalidation_0-mlogloss:2.296214\n",
      "[60]\tvalidation_0-mlogloss:2.293486\n",
      "[70]\tvalidation_0-mlogloss:2.291398\n",
      "[80]\tvalidation_0-mlogloss:2.291249\n",
      "[90]\tvalidation_0-mlogloss:2.290825\n",
      "[100]\tvalidation_0-mlogloss:2.290396\n",
      "[110]\tvalidation_0-mlogloss:2.290698\n",
      "[120]\tvalidation_0-mlogloss:2.291467\n",
      "Stopping. Best iteration:\n",
      "[104]\tvalidation_0-mlogloss:2.290112\n",
      "\n",
      "subsample - 1.0, colsample_bytree - 0.9\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.071566\n",
      "[10]\tvalidation_0-mlogloss:2.410373\n",
      "[20]\tvalidation_0-mlogloss:2.331633\n",
      "[30]\tvalidation_0-mlogloss:2.312168\n",
      "[40]\tvalidation_0-mlogloss:2.303288\n",
      "[50]\tvalidation_0-mlogloss:2.298697\n",
      "[60]\tvalidation_0-mlogloss:2.295632\n",
      "[70]\tvalidation_0-mlogloss:2.293444\n",
      "[80]\tvalidation_0-mlogloss:2.292226\n",
      "[90]\tvalidation_0-mlogloss:2.292108\n",
      "[100]\tvalidation_0-mlogloss:2.291617\n",
      "[110]\tvalidation_0-mlogloss:2.292910\n",
      "[120]\tvalidation_0-mlogloss:2.293505\n",
      "Stopping. Best iteration:\n",
      "[100]\tvalidation_0-mlogloss:2.291617\n",
      "\n",
      "subsample - 1.0, colsample_bytree - 1.0\n",
      "Will train until validation_0 error hasn't decreased in 20 rounds.\n",
      "[0]\tvalidation_0-mlogloss:3.061764\n",
      "[10]\tvalidation_0-mlogloss:2.414030\n",
      "[20]\tvalidation_0-mlogloss:2.335714\n",
      "[30]\tvalidation_0-mlogloss:2.314391\n",
      "[40]\tvalidation_0-mlogloss:2.305307\n",
      "[50]\tvalidation_0-mlogloss:2.301701\n",
      "[60]\tvalidation_0-mlogloss:2.297685\n",
      "[70]\tvalidation_0-mlogloss:2.295920\n",
      "[80]\tvalidation_0-mlogloss:2.294401\n",
      "[90]\tvalidation_0-mlogloss:2.293968\n",
      "[100]\tvalidation_0-mlogloss:2.294407\n",
      "[110]\tvalidation_0-mlogloss:2.295005\n",
      "Stopping. Best iteration:\n",
      "[92]\tvalidation_0-mlogloss:2.293897\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores5 = pd.DataFrame(columns=['score', 'ntree', 'subsample', 'colsample_bytree'])\n",
    "for s in [0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "    for cb in [0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "        sys.stderr.write('subsample - {}, colsample_bytree - {}\\n'.format(s, cb))\n",
    "\n",
    "        model = MultiClassXGB(n_estimators=1000, learning_rate=0.3, max_depth=6, min_child_weight=5, gamma=0.4,\n",
    "            subsample=s, colsample_bytree=cb\n",
    "        )\n",
    "        model.set_classes(y).set_eval(X_eval, y_eval, early_stopping_rounds=20)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        scores5 = scores5.append({\n",
    "            'subsample': s,\n",
    "            'colsample_bytree': cb,\n",
    "            'score': model.booster().best_score,\n",
    "            'ntree': model.booster().best_ntree_limit,\n",
    "        }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>ntree</th>\n",
       "      <th>subsample</th>\n",
       "      <th>colsample_bytree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.290112</td>\n",
       "      <td>105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.291617</td>\n",
       "      <td>101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.292213</td>\n",
       "      <td>82</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.292366</td>\n",
       "      <td>87</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.292894</td>\n",
       "      <td>93</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.293443</td>\n",
       "      <td>80</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.293897</td>\n",
       "      <td>93</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.294567</td>\n",
       "      <td>98</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.294578</td>\n",
       "      <td>79</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.296692</td>\n",
       "      <td>80</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.297379</td>\n",
       "      <td>86</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.297521</td>\n",
       "      <td>80</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.297590</td>\n",
       "      <td>78</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.297657</td>\n",
       "      <td>69</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.299277</td>\n",
       "      <td>73</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.300011</td>\n",
       "      <td>80</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.301362</td>\n",
       "      <td>80</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.301989</td>\n",
       "      <td>73</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.302795</td>\n",
       "      <td>64</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.304605</td>\n",
       "      <td>73</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.304997</td>\n",
       "      <td>62</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.305092</td>\n",
       "      <td>80</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.306016</td>\n",
       "      <td>63</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.306458</td>\n",
       "      <td>64</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.309997</td>\n",
       "      <td>59</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score  ntree  subsample  colsample_bytree\n",
       "22  2.290112    105        1.0               0.8\n",
       "23  2.291617    101        1.0               0.9\n",
       "20  2.292213     82        1.0               0.6\n",
       "21  2.292366     87        1.0               0.7\n",
       "15  2.292894     93        0.9               0.6\n",
       "16  2.293443     80        0.9               0.7\n",
       "24  2.293897     93        1.0               1.0\n",
       "17  2.294567     98        0.9               0.8\n",
       "18  2.294578     79        0.9               0.9\n",
       "10  2.296692     80        0.8               0.6\n",
       "19  2.297379     86        0.9               1.0\n",
       "12  2.297521     80        0.8               0.8\n",
       "14  2.297590     78        0.8               1.0\n",
       "11  2.297657     69        0.8               0.7\n",
       "13  2.299277     73        0.8               0.9\n",
       "5   2.300011     80        0.7               0.6\n",
       "6   2.301362     80        0.7               0.7\n",
       "7   2.301989     73        0.7               0.8\n",
       "8   2.302795     64        0.7               0.9\n",
       "0   2.304605     73        0.6               0.6\n",
       "9   2.304997     62        0.7               1.0\n",
       "2   2.305092     80        0.6               0.8\n",
       "3   2.306016     63        0.6               0.9\n",
       "1   2.306458     64        0.6               0.7\n",
       "4   2.309997     59        0.6               1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores5.sort_values('score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until validation_0 error hasn't decreased in 150 rounds.\n",
      "[900]\tvalidation_0-merror:0.677798\tvalidation_0-mlogloss:2.228914\n",
      "[910]\tvalidation_0-merror:0.677720\tvalidation_0-mlogloss:2.228728\n",
      "[920]\tvalidation_0-merror:0.677875\tvalidation_0-mlogloss:2.228631\n",
      "[930]\tvalidation_0-merror:0.678225\tvalidation_0-mlogloss:2.228531\n",
      "[940]\tvalidation_0-merror:0.677836\tvalidation_0-mlogloss:2.228343\n",
      "[950]\tvalidation_0-merror:0.677798\tvalidation_0-mlogloss:2.228211\n",
      "[960]\tvalidation_0-merror:0.677565\tvalidation_0-mlogloss:2.228080\n",
      "[970]\tvalidation_0-merror:0.677332\tvalidation_0-mlogloss:2.227924\n",
      "[980]\tvalidation_0-merror:0.677681\tvalidation_0-mlogloss:2.227772\n",
      "[990]\tvalidation_0-merror:0.677565\tvalidation_0-mlogloss:2.227630\n",
      "[1000]\tvalidation_0-merror:0.677487\tvalidation_0-mlogloss:2.227471\n",
      "[1010]\tvalidation_0-merror:0.677448\tvalidation_0-mlogloss:2.227314\n",
      "[1020]\tvalidation_0-merror:0.677565\tvalidation_0-mlogloss:2.227192\n",
      "[1030]\tvalidation_0-merror:0.677332\tvalidation_0-mlogloss:2.227048\n",
      "[1040]\tvalidation_0-merror:0.677603\tvalidation_0-mlogloss:2.226908\n",
      "[1050]\tvalidation_0-merror:0.677565\tvalidation_0-mlogloss:2.226800\n",
      "[1060]\tvalidation_0-merror:0.677603\tvalidation_0-mlogloss:2.226707\n",
      "[1070]\tvalidation_0-merror:0.677603\tvalidation_0-mlogloss:2.226646\n",
      "[1080]\tvalidation_0-merror:0.677759\tvalidation_0-mlogloss:2.226491\n",
      "[1090]\tvalidation_0-merror:0.677720\tvalidation_0-mlogloss:2.226430\n",
      "[1100]\tvalidation_0-merror:0.677526\tvalidation_0-mlogloss:2.226289\n",
      "[1110]\tvalidation_0-merror:0.677448\tvalidation_0-mlogloss:2.226238\n",
      "[1120]\tvalidation_0-merror:0.677021\tvalidation_0-mlogloss:2.226124\n",
      "[1130]\tvalidation_0-merror:0.677099\tvalidation_0-mlogloss:2.226022\n",
      "[1140]\tvalidation_0-merror:0.677099\tvalidation_0-mlogloss:2.225900\n",
      "[1150]\tvalidation_0-merror:0.676982\tvalidation_0-mlogloss:2.225782\n",
      "[1160]\tvalidation_0-merror:0.676982\tvalidation_0-mlogloss:2.225638\n",
      "[1170]\tvalidation_0-merror:0.676827\tvalidation_0-mlogloss:2.225566\n",
      "[1180]\tvalidation_0-merror:0.676594\tvalidation_0-mlogloss:2.225460\n",
      "[1190]\tvalidation_0-merror:0.676516\tvalidation_0-mlogloss:2.225366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiClassXGB(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "       gamma=0.4, learning_rate=0.05, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=5, missing=None, n_estimators=300, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=42, silent=True, subsample=1.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_week_set():\n",
    "    sel = random_weeks_select(X)\n",
    "    return X[~sel], X[sel], y[~sel], y[sel]\n",
    "\n",
    "X_train, X_eval, y_train, y_eval = data.store.load_or_create('week_set', get_week_set)\n",
    "\n",
    "model = MultiClassXGB(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    min_child_weight=5,\n",
    "    gamma=0.4,\n",
    "    subsample=1.0,\n",
    "    colsample_bytree=0.8,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "model.set_classes(y)\n",
    "model.set_eval(X_eval, y_eval, early_stopping_rounds=150)\n",
    "model.set_model_file('tune')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# [299] validation_0-mlogloss:2.256305\n",
    "# [590] validation_0-merror:0.680982 validation_0-mlogloss:2.237147\n",
    "# [890] validation_0-merror:0.678031 validation_0-mlogloss:2.228999\n",
    "# [1190] validation_0-merror:0.676516 validation_0-mlogloss:2.225366"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiClassXGB(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.8,\n",
       "       gamma=0.4, learning_rate=0.05, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=5, missing=None, n_estimators=300, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=42, silent=True, subsample=1.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultiClassXGB(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    min_child_weight=5,\n",
    "    gamma=0.4,\n",
    "    subsample=1.0,\n",
    "    colsample_bytree=0.8,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "model.set_classes(y)\n",
    "model.set_model_file('tune_4_1')\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7d7d4d77d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAboAAAEhCAYAAAAJVmUFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSbT/A8WY9GX4jocqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d7d4d7990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.plot_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ARSON</th>\n",
       "      <th>ASSAULT</th>\n",
       "      <th>BAD CHECKS</th>\n",
       "      <th>BRIBERY</th>\n",
       "      <th>BURGLARY</th>\n",
       "      <th>DISORDERLY CONDUCT</th>\n",
       "      <th>DRIVING UNDER THE INFLUENCE</th>\n",
       "      <th>DRUG/NARCOTIC</th>\n",
       "      <th>DRUNKENNESS</th>\n",
       "      <th>EMBEZZLEMENT</th>\n",
       "      <th>...</th>\n",
       "      <th>SEX OFFENSES NON FORCIBLE</th>\n",
       "      <th>STOLEN PROPERTY</th>\n",
       "      <th>SUICIDE</th>\n",
       "      <th>SUSPICIOUS OCC</th>\n",
       "      <th>TREA</th>\n",
       "      <th>TRESPASS</th>\n",
       "      <th>VANDALISM</th>\n",
       "      <th>VEHICLE THEFT</th>\n",
       "      <th>WARRANTS</th>\n",
       "      <th>WEAPON LAWS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.122841</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.065969</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.013901</td>\n",
       "      <td>0.010474</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.004745</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.042986</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>0.045673</td>\n",
       "      <td>0.318457</td>\n",
       "      <td>0.027303</td>\n",
       "      <td>0.017185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.077429</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>0.003880</td>\n",
       "      <td>0.036881</td>\n",
       "      <td>0.030481</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.009690</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.039812</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.008881</td>\n",
       "      <td>0.008646</td>\n",
       "      <td>0.085701</td>\n",
       "      <td>0.033211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009283</td>\n",
       "      <td>0.123755</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.096037</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>0.015554</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.006427</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.036305</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.014386</td>\n",
       "      <td>0.079541</td>\n",
       "      <td>0.041713</td>\n",
       "      <td>0.015298</td>\n",
       "      <td>0.005823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.239127</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.005788</td>\n",
       "      <td>0.032898</td>\n",
       "      <td>0.005863</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.016407</td>\n",
       "      <td>0.013621</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.005324</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.044885</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>0.080681</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.021654</td>\n",
       "      <td>0.024996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.239127</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.005788</td>\n",
       "      <td>0.032898</td>\n",
       "      <td>0.005863</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>0.016407</td>\n",
       "      <td>0.013621</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.005324</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.044885</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>0.080681</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.021654</td>\n",
       "      <td>0.024996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ARSON   ASSAULT  BAD CHECKS   BRIBERY  BURGLARY  DISORDERLY CONDUCT  \\\n",
       "Id                                                                           \n",
       "0   0.002242  0.122841    0.000008  0.001162  0.065969            0.000453   \n",
       "1   0.000373  0.077429    0.000003  0.000541  0.002388            0.003880   \n",
       "2   0.009283  0.123755    0.000008  0.000443  0.096037            0.000895   \n",
       "3   0.003299  0.239127    0.000025  0.005788  0.032898            0.005863   \n",
       "4   0.003299  0.239127    0.000025  0.005788  0.032898            0.005863   \n",
       "\n",
       "    DRIVING UNDER THE INFLUENCE  DRUG/NARCOTIC  DRUNKENNESS  EMBEZZLEMENT  \\\n",
       "Id                                                                          \n",
       "0                      0.013901       0.010474     0.003134      0.000931   \n",
       "1                      0.036881       0.030481     0.002040      0.000026   \n",
       "2                      0.001073       0.015554     0.004704      0.000061   \n",
       "3                      0.001932       0.016407     0.013621      0.000089   \n",
       "4                      0.001932       0.016407     0.013621      0.000089   \n",
       "\n",
       "       ...       SEX OFFENSES NON FORCIBLE  STOLEN PROPERTY   SUICIDE  \\\n",
       "Id     ...                                                              \n",
       "0      ...                        0.000008         0.004745  0.000041   \n",
       "1      ...                        0.000012         0.009690  0.000023   \n",
       "2      ...                        0.000004         0.006427  0.000231   \n",
       "3      ...                        0.000024         0.005324  0.000121   \n",
       "4      ...                        0.000024         0.005324  0.000121   \n",
       "\n",
       "    SUSPICIOUS OCC      TREA  TRESPASS  VANDALISM  VEHICLE THEFT  WARRANTS  \\\n",
       "Id                                                                           \n",
       "0         0.042986  0.000013  0.002789   0.045673       0.318457  0.027303   \n",
       "1         0.039812  0.000042  0.000705   0.008881       0.008646  0.085701   \n",
       "2         0.036305  0.000004  0.014386   0.079541       0.041713  0.015298   \n",
       "3         0.044885  0.000002  0.003679   0.080681       0.088000  0.021654   \n",
       "4         0.044885  0.000002  0.003679   0.080681       0.088000  0.021654   \n",
       "\n",
       "    WEAPON LAWS  \n",
       "Id               \n",
       "0      0.017185  \n",
       "1      0.033211  \n",
       "2      0.005823  \n",
       "3      0.024996  \n",
       "4      0.024996  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_proba(model, X):\n",
    "    proba = model.predict_proba(X)\n",
    "    proba_df = pd.DataFrame(proba, index=X.index, columns=model.classes_)\n",
    "\n",
    "    proba_df.index.name = 'Id'\n",
    "    return proba_df\n",
    "\n",
    "def submit_model(model, name, float_format='%.6f'):\n",
    "    proba = get_proba(model, get_X('test'))\n",
    "    proba.to_csv('./output/{}.csv.gz'.format(name), compression='gzip', float_format=float_format)\n",
    "    return proba\n",
    "\n",
    "proba = submit_model(model, 'xgb_tune_4_1')\n",
    "proba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.store.save(model, 'model_xgb_tune_4_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
